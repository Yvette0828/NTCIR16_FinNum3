{"cells":[{"cell_type":"markdown","metadata":{"id":"ny73UJb4m46T"},"source":["# Data \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2331,"status":"ok","timestamp":1640672884349,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"GTpVwTzki8rH","outputId":"49112e43-6957-4f54-92af-2ef94d306454"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":436,"status":"ok","timestamp":1640672893037,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"FfHCwD8EjG59","outputId":"9447b08e-e1a2-4f10-9d72-b098de840be8"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-0817d3c3-ab20-418a-a79d-97037d247c9f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>paragraph</th>\n","      <th>target_num</th>\n","      <th>category</th>\n","      <th>offset_start</th>\n","      <th>offset_end</th>\n","      <th>claim</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Good day and welcome to the Apple Inc. Third Q...</td>\n","      <td>2018.0</td>\n","      <td>date</td>\n","      <td>65</td>\n","      <td>69</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Please note that some of the information you'l...</td>\n","      <td>10.0</td>\n","      <td>other</td>\n","      <td>504</td>\n","      <td>506</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Please note that some of the information you'l...</td>\n","      <td>8.0</td>\n","      <td>other</td>\n","      <td>536</td>\n","      <td>537</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Thank you Nancy and thanks to everyone for joi...</td>\n","      <td>53.3</td>\n","      <td>money</td>\n","      <td>212</td>\n","      <td>216</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Thank you Nancy and thanks to everyone for joi...</td>\n","      <td>3.0</td>\n","      <td>date</td>\n","      <td>243</td>\n","      <td>244</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>8332</th>\n","      <td>Our momentum in pharmacy care services was exc...</td>\n","      <td>2018.0</td>\n","      <td>date</td>\n","      <td>56</td>\n","      <td>60</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8333</th>\n","      <td>Our momentum in pharmacy care services was exc...</td>\n","      <td>98.0</td>\n","      <td>quantity_relative</td>\n","      <td>102</td>\n","      <td>104</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8334</th>\n","      <td>Our momentum in pharmacy care services was exc...</td>\n","      <td>2020.0</td>\n","      <td>date</td>\n","      <td>282</td>\n","      <td>286</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8335</th>\n","      <td>In care delivery our clinical leaders are appl...</td>\n","      <td>99.0</td>\n","      <td>quantity_relative</td>\n","      <td>212</td>\n","      <td>214</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8336</th>\n","      <td>In care delivery our clinical leaders are appl...</td>\n","      <td>4.0</td>\n","      <td>other</td>\n","      <td>297</td>\n","      <td>298</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8337 rows × 6 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0817d3c3-ab20-418a-a79d-97037d247c9f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0817d3c3-ab20-418a-a79d-97037d247c9f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0817d3c3-ab20-418a-a79d-97037d247c9f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                              paragraph  ...  claim\n","0     Good day and welcome to the Apple Inc. Third Q...  ...      0\n","1     Please note that some of the information you'l...  ...      0\n","2     Please note that some of the information you'l...  ...      0\n","3     Thank you Nancy and thanks to everyone for joi...  ...      0\n","4     Thank you Nancy and thanks to everyone for joi...  ...      0\n","...                                                 ...  ...    ...\n","8332  Our momentum in pharmacy care services was exc...  ...      0\n","8333  Our momentum in pharmacy care services was exc...  ...      0\n","8334  Our momentum in pharmacy care services was exc...  ...      0\n","8335  In care delivery our clinical leaders are appl...  ...      0\n","8336  In care delivery our clinical leaders are appl...  ...      0\n","\n","[8337 rows x 6 columns]"]},"metadata":{},"execution_count":9}],"source":["import pandas as pd\n","import json\n","from pandas import json_normalize\n","\n","df_train = pd.read_json('/content/drive/MyDrive/NTPUIM/NTCIR/FinNUM 3/Dataset/FinNum-3_ConCall_train.json') #Results contain the required data\n","df_train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":605,"status":"ok","timestamp":1640672898427,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"7-_RxAt_jL8c","outputId":"180e3fe0-550c-49df-d34f-2849012c1b45"},"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-99f2a64e-d520-4253-8f52-2d1df5f4a4cf\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>paragraph</th>\n","      <th>target_num</th>\n","      <th>category</th>\n","      <th>offset_start</th>\n","      <th>offset_end</th>\n","      <th>claim</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>In care delivery our clinical leaders are appl...</td>\n","      <td>80.0</td>\n","      <td>other</td>\n","      <td>373</td>\n","      <td>375</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>We achieved significantly lower total medical ...</td>\n","      <td>30.0</td>\n","      <td>relative</td>\n","      <td>139</td>\n","      <td>141</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>By 2030 there will be over 80 million people i...</td>\n","      <td>2030.0</td>\n","      <td>date</td>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>By 2030 there will be over 80 million people i...</td>\n","      <td>80.0</td>\n","      <td>quantity_absolute</td>\n","      <td>27</td>\n","      <td>29</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>By 2030 there will be over 80 million people i...</td>\n","      <td>3.0</td>\n","      <td>quantity_absolute</td>\n","      <td>62</td>\n","      <td>63</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1186</th>\n","      <td>Now let's move to a summary of the consolidate...</td>\n","      <td>126.0</td>\n","      <td>money</td>\n","      <td>220</td>\n","      <td>223</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1187</th>\n","      <td>On a comparable basis excluding divestitures a...</td>\n","      <td>2.0</td>\n","      <td>relative</td>\n","      <td>115</td>\n","      <td>116</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1188</th>\n","      <td>On a comparable basis excluding divestitures a...</td>\n","      <td>45.1</td>\n","      <td>absolute</td>\n","      <td>226</td>\n","      <td>230</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1189</th>\n","      <td>On a comparable basis excluding divestitures a...</td>\n","      <td>35.7</td>\n","      <td>absolute</td>\n","      <td>283</td>\n","      <td>287</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1190</th>\n","      <td>On a comparable basis excluding divestitures a...</td>\n","      <td>35.5</td>\n","      <td>absolute</td>\n","      <td>332</td>\n","      <td>336</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1191 rows × 6 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99f2a64e-d520-4253-8f52-2d1df5f4a4cf')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-99f2a64e-d520-4253-8f52-2d1df5f4a4cf button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-99f2a64e-d520-4253-8f52-2d1df5f4a4cf');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                              paragraph  ...  claim\n","0     In care delivery our clinical leaders are appl...  ...      0\n","1     We achieved significantly lower total medical ...  ...      0\n","2     By 2030 there will be over 80 million people i...  ...      0\n","3     By 2030 there will be over 80 million people i...  ...      1\n","4     By 2030 there will be over 80 million people i...  ...      0\n","...                                                 ...  ...    ...\n","1186  Now let's move to a summary of the consolidate...  ...      0\n","1187  On a comparable basis excluding divestitures a...  ...      0\n","1188  On a comparable basis excluding divestitures a...  ...      0\n","1189  On a comparable basis excluding divestitures a...  ...      0\n","1190  On a comparable basis excluding divestitures a...  ...      0\n","\n","[1191 rows x 6 columns]"]},"metadata":{},"execution_count":10}],"source":["df_dev = pd.read_json('/content/drive/MyDrive/NTPUIM/NTCIR/FinNUM 3/Dataset/FinNum-3_ConCall_dev.json') #Results contain the required data\n","df_dev"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":990,"status":"ok","timestamp":1640672404559,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"oqEVM-LejSAk","outputId":"7cef0653-2918-49ee-eb43-058d596323b0"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-c1ba045a-8b5c-470e-b288-05ad321bbd33\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>paragraph</th>\n","      <th>target_num</th>\n","      <th>offset_start</th>\n","      <th>offset_end</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Let's turn now to our wireless results on slid...</td>\n","      <td>6.0</td>\n","      <td>48</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>In the fourth quarter total wireless operating...</td>\n","      <td>1.7</td>\n","      <td>65</td>\n","      <td>68</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>In the fourth quarter total wireless operating...</td>\n","      <td>23.8</td>\n","      <td>74</td>\n","      <td>78</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>In the fourth quarter total wireless operating...</td>\n","      <td>87.5</td>\n","      <td>187</td>\n","      <td>191</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>In the fourth quarter total wireless operating...</td>\n","      <td>1.9</td>\n","      <td>213</td>\n","      <td>216</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2378</th>\n","      <td>We're also combining the project organizations...</td>\n","      <td>2.0</td>\n","      <td>415</td>\n","      <td>416</td>\n","    </tr>\n","    <tr>\n","      <th>2379</th>\n","      <td>With the increased upside particularly in the ...</td>\n","      <td>30.0</td>\n","      <td>88</td>\n","      <td>90</td>\n","    </tr>\n","    <tr>\n","      <th>2380</th>\n","      <td>With the increased upside particularly in the ...</td>\n","      <td>2019.0</td>\n","      <td>102</td>\n","      <td>106</td>\n","    </tr>\n","    <tr>\n","      <th>2381</th>\n","      <td>With the increased upside particularly in the ...</td>\n","      <td>2.0</td>\n","      <td>129</td>\n","      <td>130</td>\n","    </tr>\n","    <tr>\n","      <th>2382</th>\n","      <td>Before I hand it back to Neil let me just offe...</td>\n","      <td>2018.0</td>\n","      <td>263</td>\n","      <td>267</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2383 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1ba045a-8b5c-470e-b288-05ad321bbd33')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c1ba045a-8b5c-470e-b288-05ad321bbd33 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c1ba045a-8b5c-470e-b288-05ad321bbd33');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                              paragraph  ...  offset_end\n","0     Let's turn now to our wireless results on slid...  ...          50\n","1     In the fourth quarter total wireless operating...  ...          68\n","2     In the fourth quarter total wireless operating...  ...          78\n","3     In the fourth quarter total wireless operating...  ...         191\n","4     In the fourth quarter total wireless operating...  ...         216\n","...                                                 ...  ...         ...\n","2378  We're also combining the project organizations...  ...         416\n","2379  With the increased upside particularly in the ...  ...          90\n","2380  With the increased upside particularly in the ...  ...         106\n","2381  With the increased upside particularly in the ...  ...         130\n","2382  Before I hand it back to Neil let me just offe...  ...         267\n","\n","[2383 rows x 4 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df_test = pd.read_json('/content/drive/MyDrive/NTPUIM/NTCIR/FinNUM 3/Dataset/FinNum-3_ConCall_test.json') #Results contain the required data\n","df_test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"elapsed":416,"status":"ok","timestamp":1640672409776,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"kmJuQDiyapLG","outputId":"aee98c89-1453-4bfc-a708-e9a1ebc89dcd"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"Please note that some of the information you'll hear during our discussion today will consist of forward-looking statements including without limitation those regarding revenue gross margin operating expenses other income and expense taxes capital allocation share repurchases dividends and future business outlook. Actual results or trends could differ materially from our forecast. For more information please refer to the risk factors discussed in Apple's most recently filed periodic reports on Form 10-K and Form 10-Q and the Form 8-K filed with the SEC today along with the associated press release.\""]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["a = df_train.iloc[1,0]\n","a"]},{"cell_type":"markdown","metadata":{"id":"MQKX1yBOm3zR"},"source":["#Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11166,"status":"ok","timestamp":1640672423362,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"getOfANIoUXc","outputId":"7d62d457-7824-4e2c-c4eb-d21db68f3c48"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 4.3 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 46.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 48.1 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 444 kB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 26.0 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.15.0\n"]}],"source":["pip install transformers"]},{"cell_type":"markdown","metadata":{"id":"ZaN_B_jmm_40"},"source":["## Tokenizer \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4mcmZ6G4m-u4","executionInfo":{"status":"ok","timestamp":1640672925166,"user_tz":-480,"elapsed":12050,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"}},"outputId":"3e6b95b4-4bb6-4c78-f5ac-354426c94f51"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["[0, 41552, 21948, 15698, 28696, 1922, 3103, 15698, 2]\n"]}],"source":["import torch\n","from transformers import RobertaModel, RobertaConfig, RobertaTokenizer\n","\n","pretrained_weights = 'roberta-base'\n","tokenizer  = RobertaTokenizer.from_pretrained(pretrained_weights)\n","model =  RobertaModel.from_pretrained(pretrained_weights)\n","\n","special_token_dict = {'additional_special_token'  : ['<#>','<$>']}\n","print(tokenizer.encode('<122> <2333>'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2321,"status":"ok","timestamp":1640672933840,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"ATn5W72X2Hjd","outputId":"aa7fe4a7-c6c7-44b8-9b04-f869e43135a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["RobertaConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n"]}],"source":["configuration = RobertaConfig()\n","model = RobertaModel(configuration)\n","configuration = model.config\n","print(configuration)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":297,"status":"ok","timestamp":1640506163122,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"3Zv_nbaeuS7Y","outputId":"44ea0781-75f0-4ab0-b43d-30fa8bdecbac"},"outputs":[{"name":"stdout","output_type":"stream","text":["['bos_token', 'eos_token', 'unk_token', 'sep_token', 'pad_token', 'cls_token', 'mask_token', 'additional_special_tokens']\n"]}],"source":["print(tokenizer.SPECIAL_TOKENS_ATTRIBUTES)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":805,"status":"ok","timestamp":1640673009240,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"zgRmcbAVwiZY","outputId":"f86a35ac-224e-4e4d-ce2a-e7fc0c69f5c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["['<122>', '<2333>']\n","[50265, 50266]\n"]}],"source":["special_token_dict = {'additional_special_tokens'  : ['<122>','<2333>'] }\n","tokenizer.add_special_tokens(special_token_dict)\n","print(tokenizer.additional_special_tokens)\n","print(tokenizer.additional_special_tokens_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1640518982155,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"5MCfwl_SxZ2j","outputId":"3b8b2360-cf14-4715-fc5c-3707097dcd10"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0, 50265, 50266, 2]\n"]}],"source":["print(tokenizer.encode('<122> <2333>'))\n","# print(tokenizer.encode('<0> this <1> '))\n","# print(tokenizer.encode('1'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":350,"status":"ok","timestamp":1640512143208,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"WxDclXWK2rp-","outputId":"7c0c32b4-983a-4961-b7c5-8ec4348d0b06"},"outputs":[{"data":{"text/plain":["50265"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.vocab_size"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":244,"status":"ok","timestamp":1640667333126,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"Fo-jBz5v4Qg6","outputId":"1986e1d4-cf41-4937-a337-e5d68722d819"},"outputs":[{"data":{"text/plain":["{'additional_special_tokens': ['<122>', '<2333>'],\n"," 'bos_token': '<s>',\n"," 'cls_token': '<s>',\n"," 'eos_token': '</s>',\n"," 'mask_token': '<mask>',\n"," 'pad_token': '<pad>',\n"," 'sep_token': '</s>',\n"," 'unk_token': '<unk>'}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.special_tokens_map"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":306,"status":"ok","timestamp":1640514860424,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"lMQxrIJO4oV9","outputId":"e7de4fde-b806-48f3-8540-acbe67fef55f"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"data":{"text/plain":["{'input_ids': tensor([[    0, 50266,  9226, 50267,     4,     2,     1,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["MAX_LEN = 10\n","sentence1 = '<0> this <1>.'\n","\n","encoded_dict = tokenizer.encode_plus(\n","            sentence1,                \n","            add_special_tokens = True,\n","            max_length = MAX_LEN,     \n","            pad_to_max_length = True,\n","            return_attention_mask = True,  \n","            return_tensors = 'pt' # return pytorch tensors\n","       )\n","\n","\n","encoded_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":277,"status":"ok","timestamp":1640515003070,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"0rHWs8eo486r","outputId":"ce8f5761-2c76-4d02-9c3a-f833b5ade611"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([    0, 50266,  9226, 50267,     4,     2,     1,     1,     1,     1])\n","tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0])\n"]}],"source":["input_ids = encoded_dict['input_ids'][0]\n","att_mask = encoded_dict['attention_mask'][0]\n","print(input_ids)\n","print(att_mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1640515005416,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"dX8meR705iKh","outputId":"29c97005-8b71-4992-b5be-b30f36b0c9ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["<s> <0> this <1>.</s><pad><pad><pad><pad>\n"]}],"source":["a = tokenizer.decode(input_ids,\n","                skip_special_tokens=False)\n","print(a)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1359,"status":"ok","timestamp":1640519065329,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"WVV7GU5gQyct","outputId":"666b8b59-adb5-42ff-e65e-843742be7536"},"outputs":[{"data":{"text/plain":["Embedding(50267, 768)"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["model.resize_token_embeddings(len(tokenizer))"]},{"cell_type":"markdown","metadata":{"id":"hZ9km_ozrnG2"},"source":["## Pre-Trained"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":389,"status":"ok","timestamp":1640673026025,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"PvQurYK-j6cs","outputId":"36b08878-fd7f-4293-9e3f-783503a8b050"},"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}],"source":["print(torch.cuda.is_available())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":247,"status":"ok","timestamp":1640667214968,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"p9nQ_WzfzJzR","outputId":"6c2e8f66-7fe1-4192-c6fe-4ae1af76b1ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n","RobertaModel(\n","  (embeddings): RobertaEmbeddings(\n","    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","    (position_embeddings): Embedding(514, 768, padding_idx=1)\n","    (token_type_embeddings): Embedding(1, 768)\n","    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): RobertaEncoder(\n","    (layer): ModuleList(\n","      (0): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): RobertaLayer(\n","        (attention): RobertaAttention(\n","          (self): RobertaSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): RobertaSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): RobertaIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): RobertaOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): RobertaPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.cuda()\n","print(device)\n","print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8-2SAEr8pRae"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import json, re\n","from tqdm import tqdm_notebook\n","from uuid import uuid4\n","\n","## Torch Modules\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn import CrossEntropyLoss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9SkKmSA1Wm1l"},"outputs":[],"source":["def prepare_features(seq_1, max_seq_length = 512, \n","             zero_pad = False, include_CLS_token = True, include_SEP_token = True):\n","    ## Tokenzine Input\n","    tokens_a = tokenizer.tokenize(seq_1)\n","\n","    ## Truncate\n","    if len(tokens_a) > max_seq_length - 2:\n","        tokens_a = tokens_a[0:(max_seq_length - 2)]\n","    ## Initialize Tokens\n","    tokens = []\n","    if include_CLS_token:\n","        tokens.append(tokenizer.cls_token)\n","    ## Add Tokens and separators\n","    for token in tokens_a:\n","        tokens.append(token)\n","\n","    if include_SEP_token:\n","        tokens.append(tokenizer.sep_token)\n","\n","    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","    ## Input Mask \n","    input_mask = [1] * len(input_ids)\n","    ## Zero-pad sequence lenght\n","    if zero_pad:\n","        while len(input_ids) < max_seq_length:\n","            input_ids.append(0)\n","            input_mask.append(0)\n","    return torch.tensor(input_ids).unsqueeze(0), input_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":391,"status":"ok","timestamp":1640673104563,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"yTMyMGrWagIA","outputId":"3467357f-8d0a-4e30-829b-83b38144f847"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[    0,  6715,  1591,    14,   103,     9,     5,   335,    47,   890,\n","           1798,   148,    84,  3221,   452,    40, 19438,     9,   556,    12,\n","           3690,  1997,   217,   396, 22830,   167,  2624,   903,  4200,  2759,\n","           1633,  4068,    97,  1425,     8,  5623,  2556,   812, 12278,   458,\n","           2851,  9222,  9354,  8599,     8,   499,   265,  3839,     4, 30144,\n","            775,    50,  3926,   115, 10356, 11463,    31,    84,  1914,     4,\n","            286,    55,   335,  2540,  9115,     7,     5,   810,  2433,  3373,\n","             11,  1257,    18,   144,   682,  1658, 27185,   690,    15,  8575,\n","            158,    12,   530,     8,  8575,   158,    12,  1864,     8,     5,\n","           8575,   290,    12,   530,  1658,    19,     5,  3614,   452,   552,\n","             19,     5,  3059,  1228,   800,     4,     2]]),\n"," [1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1,\n","  1])"]},"metadata":{},"execution_count":18}],"source":["prepare_features(\"Please note that some of the information youll hear during our discussion today will consist of forward-looking statements including without limitation those regarding revenue gross margin operating expenses other income and expense taxes capital allocation share repurchases dividends and future business outlook. Actual results or trends could differ materially from our forecast. For more information please refer to the risk factors discussed in Apple's most recently filed periodic reports on Form 10-K and Form 10-Q and the Form 8-K filed with the SEC today along with the associated press release.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"muAmW4NXwyBV"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","def split_dataset(df):\n","    train_set, x = train_test_split(df, \n","        stratify=df_train['claim'],\n","        test_size=0.2, \n","        random_state=42)\n","    val_set, test_set = train_test_split(x, \n","        stratify=x['claim'],\n","        test_size=0.5, \n","        random_state=43)\n","\n","    return train_set,val_set, test_set\n","\n","\n","\n","train_data,val_data, test_data = split_dataset(df_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oD6YMyu9Qngn"},"outputs":[],"source":["test_data.reset_index(drop=True,inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":234,"status":"ok","timestamp":1640656922048,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"sDMrTwdGxYV9","outputId":"f0b0cdf5-6547-4842-d855-a793fdc66d15"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                              paragraph  ...  claim\n","6586  So now let's turn to EMEA. In EMEA Q1 revenue ...  ...      0\n","7190  In addition both Ibrance and Xeljanz revenues ...  ...      0\n","7171  Moving on to key takeaways. We delivered solid...  ...      0\n","1833  Revenue of $5.4 billion was up 6% organically....  ...      0\n","1933  Turning to Slide 3. This is a game of inches a...  ...      0\n","1175  At Parks and Resorts revenues increased 6% and...  ...      0\n","3584  Turning to free cash flow. We expect about $12...  ...      0\n","4438  In Orthopaedics excluding the impact of acquis...  ...      0\n","4215  We now expect a full year tax rate of 13% 1 po...  ...      1\n","7777  We plan to deliver another year of 90% or bett...  ...      0\n","\n","[10 rows x 6 columns]\n"]}],"source":["print(test_data.sample(10))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K-6XWP03pPFr"},"outputs":[],"source":["class Intents(Dataset):\n","    def __init__(self, dataframe):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        \n","    def __getitem__(self, index):\n","        paragraph = self.data.paragraph[index]\n","        claim = self.data.claim[index]\n","        X, _  = prepare_features(paragraph)\n","        y = self.data.claim[index]\n","        return X, y\n","    \n","    def __len__(self):\n","        return self.len"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":238,"status":"ok","timestamp":1640656772136,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"RfdXL4TJrHoz","outputId":"d44ced42-bbcf-4fc9-d01d-acc48074c2af"},"outputs":[{"data":{"text/plain":["(8337, 6)"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["df_train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":387,"status":"ok","timestamp":1640673121490,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"3KVxt7JBw7-1","outputId":"d9ac7b02-c9ef-475c-c911-81f81f2fcc25"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6669, 6)"]},"metadata":{},"execution_count":21}],"source":["train_data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":381,"status":"ok","timestamp":1640673125392,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"tZToaHz4q0A6","outputId":"79eb5bde-647e-4f00-b483-d013674ee413"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 28])\n"]}],"source":["training_set = Intents(train_data)\n","print(training_set.__getitem__(0)[0].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":424,"status":"ok","timestamp":1640673139666,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"wuzPhg09wn0N","outputId":"a96fcaec-4ca4-41f9-d48a-4b127930cbd7"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 82])\n"]}],"source":["testing_set = Intents(test_data)\n","print(testing_set.__getitem__(0)[0].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1640673143960,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"Z1XfuAp4rQHr","outputId":"650a5102-108c-48a0-e20b-56432a9b0c3f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[    0, 12350,   183,     8,  2814,     7,     5,  1257,   603,     4,\n","           7470, 10830, 22528,  2041,   199,  7535,  1033,  2815,  3310,     4,\n","           2477,    18,   486,    16,   145,  2673,     4,     2]]), 0)"]},"metadata":{},"execution_count":26}],"source":["training_set.__getitem__(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":940,"status":"ok","timestamp":1640673159209,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"YSC8LNZ1xq9s","outputId":"c676ea1a-82ed-4d9d-b8c6-f7529c981c7e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 28, 768])"]},"metadata":{},"execution_count":28}],"source":["model(training_set.__getitem__(0)[0])[0].size()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1640666678092,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"9HMysluHWrjA","outputId":"d4a8367b-b957-4a3c-ba2d-23fc22d75287"},"outputs":[{"data":{"text/plain":["<__main__.Intents at 0x7f88606e3990>"]},"execution_count":84,"metadata":{},"output_type":"execute_result"}],"source":["training_set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fN5XtLM_wQ9e"},"outputs":[],"source":["training_loader = DataLoader(training_set, batch_size = 1, shuffle = False, drop_last = False)\n","testing_loader = DataLoader(testing_set, batch_size = 1, shuffle = True, drop_last = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":243,"status":"ok","timestamp":1640668516190,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"WdFo3pvXdhlF","outputId":"e3e31b2d-53ad-4968-b5fe-d5be1f44de9c"},"outputs":[{"data":{"text/plain":["1112"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["len(training_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":431,"status":"error","timestamp":1640673206790,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"QP1QCUfKPZEZ","outputId":"275a506a-b6c8-4a23-8b25-c8205e797a51"},"outputs":[{"output_type":"stream","name":"stdout","text":["sent:  tensor([[[    0, 12350,   183,     8,  2814,     7,     5,  1257,   603,     4,\n","           7470, 10830, 22528,  2041,   199,  7535,  1033,  2815,  3310,     4,\n","           2477,    18,   486,    16,   145,  2673,     4,     2]]])\n","Label: tensor([0])\n","i: 0\n","sent:  tensor([[[    0,  6715,  1591,    14,   103,     9,     5,   335,    47,   581,\n","           1798,   148,    84,  3221,   452,    40, 19438,     9,   556,    12,\n","           3690,  1997,   217,   396, 22830,   167,  2624,   903,  4200,  2759,\n","           1633,  4068,    97,  1425,     8,  5623,  2556,   812, 12278,   458,\n","           2851,  9222,  9354,  8599,     8,   499,   265,  3839,     4, 30144,\n","            775,    50,  3926,   115, 10356, 11463,    31,    84,  1914,     4,\n","            286,    55,   335,  2540,  9115,     7,     5,   810,  2433,  3373,\n","             11,  1257,    18,   144,   682,  1658, 27185,   690,    15,  8575,\n","            158,    12,   530,     8,  8575,   158,    12,  1864,     8,     5,\n","           8575,   290,    12,   530,  1658,    19,     5,  3614,   452,   552,\n","             19,     5,  3059,  1228,   800,     4,     2]]])\n","Label: tensor([0])\n","i: 1\n","sent:  tensor([[[    0,  6715,  1591,    14,   103,     9,     5,   335,    47,   581,\n","           1798,   148,    84,  3221,   452,    40, 19438,     9,   556,    12,\n","           3690,  1997,   217,   396, 22830,   167,  2624,   903,  4200,  2759,\n","           1633,  4068,    97,  1425,     8,  5623,  2556,   812, 12278,   458,\n","           2851,  9222,  9354,  8599,     8,   499,   265,  3839,     4, 30144,\n","            775,    50,  3926,   115, 10356, 11463,    31,    84,  1914,     4,\n","            286,    55,   335,  2540,  9115,     7,     5,   810,  2433,  3373,\n","             11,  1257,    18,   144,   682,  1658, 27185,   690,    15,  8575,\n","            158,    12,   530,     8,  8575,   158,    12,  1864,     8,     5,\n","           8575,   290,    12,   530,  1658,    19,     5,  3614,   452,   552,\n","             19,     5,  3059,  1228,   800,     4,     2]]])\n","Label: tensor([0])\n","i: 2\n"]},{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 3","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-7637db896333>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sent: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Label:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-de2e44312ebf>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mparagraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mclaim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclaim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mprepare_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 3"]}],"source":["for i, (sent, label) in enumerate(training_loader):\n","        print('sent: ',sent)\n","        print('Label:', label)\n","        print('i:',i)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1640664847108,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"8imy7HjcPqPg","outputId":"cf17f91f-96a0-4ec4-db5e-2ec8291a75a7"},"outputs":[{"data":{"text/plain":["<torch.utils.data.dataloader.DataLoader at 0x7f8865102990>"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["training_loader\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ys0GYDJ8y1qQ"},"outputs":[],"source":["loss_function = nn.CrossEntropyLoss()\n","learning_rate = 1e-05\n","optimizer = optim.Adam(params =  model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":394,"status":"ok","timestamp":1640673235386,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"9x1x9Rgyy3yM","outputId":"b8b4dc44-a936-448e-d784-0f714c09b8be"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 28, 768])\n"]}],"source":["inp = training_set.__getitem__(0)[0]\n","output = model(inp)[0]\n","print(output.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2441,"status":"ok","timestamp":1640667412936,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"KGl2Q4yCbL5V","outputId":"0bad5c39-4634-440d-dc98-1f40e2aa7236"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["pretrained_weights = 'roberta-base'\n","NUM_LABELS = 2\n","model =  RobertaModel.from_pretrained(pretrained_weights,num_labels=NUM_LABELS)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":239,"status":"ok","timestamp":1640656673150,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"aBJxyMJ8d5Es","outputId":"5b679edb-0c93-4c5e-b397-6df100eb6aaa"},"outputs":[{"data":{"text/plain":["RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.15.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["model.config"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":605,"referenced_widgets":["99a5273935014d148e399acfbce9c1e1","1d384f428cbe40f995c7f14869a096d9","1efd75dabcc34d72b324f7006886d375","b78ac1dbfef94f7a9c5860ce3972ec63","d3bf511c8695407bb2a278c225a9291a","d4a9cf5c20534d7bb9718670af71b242","5a1a8e73c51e4f89afc1e36dbb28724e","0504874057f84be7aa680b97ae1e4d14","efca09a696ac4d9787ab93a9c9218001","1b11d814daed43b3849cbc270f6d3182","de074b7299524ff5aae5a075085397a4"]},"executionInfo":{"elapsed":977,"status":"error","timestamp":1640673919454,"user":{"displayName":"vivian teng vivian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg60IJfNXc6jatRL4iSi7wvPYHxEEfo4Z2Bh09I3NA=s64","userId":"08553140932024934221"},"user_tz":-480},"id":"ASbKFBvwzZxh","outputId":"e6a70d2f-180a-4e17-cdb6-3a53454b0270"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  after removing the cwd from sys.path.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"99a5273935014d148e399acfbce9c1e1","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["EPOCH -- 0\n","sent:  tensor([[[    0, 12350,   183,     8,  2814,     7,     5,  1257,   603,     4,\n","           7470, 10830, 22528,  2041,   199,  7535,  1033,  2815,  3310,     4,\n","           2477,    18,   486,    16,   145,  2673,     4,     2]]])\n","Label: tensor([0])\n","output: torch.Size([1, 28, 768])\n","label: tensor([0])\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-c96623d0a541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected target size [1, 768], got [1]"]}],"source":["max_epochs = 3\n","model = model.train()\n","loss_function = CrossEntropyLoss()\n","for epoch in tqdm_notebook(range(max_epochs)):\n","    print(\"EPOCH -- {}\".format(epoch))\n","    for i, (sent, label) in enumerate(training_loader):\n","        print('sent: ',sent)\n","        print('Label:', label)\n","        optimizer.zero_grad()\n","        sent = sent.squeeze(0)\n","        if torch.cuda.is_available():\n","          sent = sent\n","          label = label\n","        output = model.forward(sent)[0]\n","        _, predicted = torch.max(output, 1)\n","        print('output:', output.shape)\n","        print('label:', label)\n","        \n","        loss = loss_function(output, label)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if i%100 == 0:\n","            correct = 0\n","            total = 0\n","            for sent, label in testing_loader:\n","                sent = sent.squeeze(0)\n","                if torch.cuda.is_available():\n","                  sent = sent.cuda()\n","                  label = label.cuda()\n","                output = model.forward(sent)[0]\n","                _, predicted = torch.max(output.data, 1)\n","                total += label.size(0)\n","                correct += (predicted.cpu() == label.cpu()).sum()\n","            accuracy = 100.00 * correct.numpy() / total\n","            print('Iteration: {}. Loss: {}. Accuracy: {}%'.format(i, loss.item(), accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gvpEirrs3Rhj"},"outputs":[],"source":["def get_predictions(model, dataloader, compute_acc=False):\n","    predictions = None\n","    correct = 0\n","    total = 0\n","      \n","    with torch.no_grad():\n","        # 遍巡整個資料集\n","        for data in dataloader:"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"FinNUM3_en_RoBERTa.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"99a5273935014d148e399acfbce9c1e1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1d384f428cbe40f995c7f14869a096d9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1efd75dabcc34d72b324f7006886d375","IPY_MODEL_b78ac1dbfef94f7a9c5860ce3972ec63","IPY_MODEL_d3bf511c8695407bb2a278c225a9291a"]}},"1d384f428cbe40f995c7f14869a096d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1efd75dabcc34d72b324f7006886d375":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d4a9cf5c20534d7bb9718670af71b242","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"  0%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5a1a8e73c51e4f89afc1e36dbb28724e"}},"b78ac1dbfef94f7a9c5860ce3972ec63":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0504874057f84be7aa680b97ae1e4d14","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":3,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_efca09a696ac4d9787ab93a9c9218001"}},"d3bf511c8695407bb2a278c225a9291a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1b11d814daed43b3849cbc270f6d3182","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/3 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_de074b7299524ff5aae5a075085397a4"}},"d4a9cf5c20534d7bb9718670af71b242":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5a1a8e73c51e4f89afc1e36dbb28724e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0504874057f84be7aa680b97ae1e4d14":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"efca09a696ac4d9787ab93a9c9218001":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1b11d814daed43b3849cbc270f6d3182":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"de074b7299524ff5aae5a075085397a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":0}